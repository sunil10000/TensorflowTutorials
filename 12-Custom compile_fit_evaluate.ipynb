{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12-Custom compile_fit_evaluate.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO1yex0R7pfbf1ywZUm+bdC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LsjgIxgcpT4-","executionInfo":{"status":"ok","timestamp":1602949462940,"user_tz":-330,"elapsed":2653,"user":{"displayName":"Sunil Meena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggf_5At3_5Lfa6Wkm1JnMhMhz9OZW6kSTTd0FDA=s64","userId":"07334191165206915992"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bodf8hRpfyf","executionInfo":{"status":"ok","timestamp":1602949463545,"user_tz":-330,"elapsed":2889,"user":{"displayName":"Sunil Meena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggf_5At3_5Lfa6Wkm1JnMhMhz9OZW6kSTTd0FDA=s64","userId":"07334191165206915992"}},"outputId":"42073eea-abe0-4955-df4a-057e1253df2b","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')/255.\n","x_test = x_test.reshape(-1, 28, 28, 1).astype('float32')/255."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j_U_MJ50pxO_","executionInfo":{"status":"ok","timestamp":1602949470121,"user_tz":-330,"elapsed":8554,"user":{"displayName":"Sunil Meena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggf_5At3_5Lfa6Wkm1JnMhMhz9OZW6kSTTd0FDA=s64","userId":"07334191165206915992"}}},"source":["model = keras.Sequential(\n","    [\n","     layers.Input(shape=(28,28,1)),\n","     layers.Conv2D(64, 3, padding='same'),\n","     layers.ReLU(),\n","     layers.Conv2D(128, 3, padding='same'),\n","     layers.ReLU(),\n","     layers.Flatten(),\n","     layers.Dense(10),\n","    ],\n","\n","    name = 'basic_model'\n","\n",")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QD4moepyqKbA"},"source":["# Custom fit"]},{"cell_type":"code","metadata":{"id":"e4KQ46aEqIXv","executionInfo":{"status":"ok","timestamp":1602949552256,"user_tz":-330,"elapsed":25678,"user":{"displayName":"Sunil Meena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggf_5At3_5Lfa6Wkm1JnMhMhz9OZW6kSTTd0FDA=s64","userId":"07334191165206915992"}},"outputId":"b025fafc-c3aa-4e58-e168-8ec487a7227d","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["class CustomFit(keras.Model):\n","  def __init__(self, model):\n","    super(CustomFit, self).__init__()\n","    self.model = model\n","  \n","  def train_step(self, data):\n","    x, y = data\n","\n","    # Forward Propagation\n","    with tf.GradientTape() as tape: # records operations for gradients\n","      y_pred = self.model(x, training=True)\n","      loss   = self.compiled_loss(y, y_pred) # loss in compile function\n","\n","    # BackPropagation    \n","    training_vars = self.trainable_variables\n","    gradients = tape.gradient(loss, training_vars)\n","    self.optimizer.apply_gradients(zip(gradients, training_vars))\n","\n","    # Updating metrics (mentioned in compile function)\n","    self.compiled_metrics.update_state(y, y_pred)\n","\n","    return {m.name : m.result() for m in self.metrics}\n","\n","\n","\n","\n","training = CustomFit(model)\n","training.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy']\n",")\n","training.fit(x_train, y_train, batch_size=32, epochs=2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1119 - accuracy: 0.9661\n","Epoch 2/2\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0424 - accuracy: 0.9872\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcc049ad7b8>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"wYUTUcarPctW"},"source":["## Custom compile_fit_evaluate <br>\n","<pre>  => compile (need to use own accuracy, loss and not compiled ones)\n","  => fit (train_step)\n","  => evaluate (test_step)\n","</pre>"]},{"cell_type":"code","metadata":{"id":"IuJ5eQavPHGM","executionInfo":{"status":"ok","timestamp":1602951014362,"user_tz":-330,"elapsed":1818,"user":{"displayName":"Sunil Meena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggf_5At3_5Lfa6Wkm1JnMhMhz9OZW6kSTTd0FDA=s64","userId":"07334191165206915992"}}},"source":["class CustomTrainer(keras.Model):\n","\n","  def __init__(self, model):\n","    super(CustomTrainer, self).__init__()\n","    self.model = model\n","  \n","  def compile(self, optimizer, loss):\n","    super(CustomTrainer, self).compile()\n","    self.optimizer = optimizer\n","    self.loss = loss\n","    self.acc_metric = keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","\n","  def train_step(self, data):\n","    x, y = data\n","\n","    # Forward Propagation\n","    with tf.GradientTape() as tape: # record operations for gradients\n","      y_pred = self.model(x, training=True)\n","      loss   = self.loss(y, y_pred) # here not compiled since custom compilation\n","    \n","    # Back Propagation\n","    training_vars = self.trainable_variables\n","    gradients = tape.gradient(loss, training_vars)\n","    self.optimizer.apply_gradients(zip(gradients, training_vars))\n","\n","    # Metrics update(custom acc_metric and not compiled_metric)\n","    self.acc_metric.update_state(y, y_pred)\n","\n","    return {'loss': loss, 'accuracy': self.acc_metric.result()}\n","\n","  def test_step(self, data):\n","    x,y = data\n","\n","    # Training is false, because BatchNormalization, Dropout etc\n","    # have different behaviour during train and test\n","    y_pred = self.model(x, training=False)\n","    loss   = self.loss(y, y_pred)\n","    self.acc_metric.update_state(y, y_pred)\n","\n","    return {'loss':loss, 'accuracy':self.acc_metric.result()}\n","\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hopThiLKThTO","executionInfo":{"status":"ok","timestamp":1602951060233,"user_tz":-330,"elapsed":19884,"user":{"displayName":"Sunil Meena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggf_5At3_5Lfa6Wkm1JnMhMhz9OZW6kSTTd0FDA=s64","userId":"07334191165206915992"}},"outputId":"a0c8c696-ecd3-4b99-e2cf-f2b034b96610","colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["model = keras.Sequential(\n","    [\n","     layers.Input(shape=(28,28,1)),\n","     layers.Conv2D(64, 3, padding='same'),\n","     layers.ReLU(),\n","     layers.Conv2D(128, 3, padding='same'),\n","     layers.ReLU(),\n","     layers.Flatten(),\n","     layers.Dense(10),\n","    ],\n","\n","    name = 'basic_model'\n","\n",")\n","\n","training = CustomTrainer(model)\n","training.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",")\n","training.fit(x_train, y_train, batch_size=32, epochs=2)\n","training.evaluate(x_test, y_test, batch_size=32)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1098 - accuracy: 0.9667\n","Epoch 2/2\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0405 - accuracy: 0.9871\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9872\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9872000217437744"]},"metadata":{"tags":[]},"execution_count":15}]}]}